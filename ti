基于RRAM的Transformer网络加速

研究背景
国内外研究现状
选题意义
研究目的
预期成果
研究方法及其论证
预计难点及预计解决措施


自2017年由谷歌团队提出带有自注意力机制的Transformer后，这具有巨大革新性的个网络迅速在NLP领域展现出其巨大优势，目前已经成为NLP领域的核心主流网络模型。
Transformer在NLP领域的亮眼表现也引起了大家对其扩展至CV领域的巨大兴趣。CNN在图像视觉任务上具有平移不变性和局部敏感性等归纳偏置。
